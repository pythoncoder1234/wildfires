{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wildfires\n",
    "\n",
    "This repository is a mess, so when in doubt, run code from the notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Format data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "def process(row):\n",
    "    return np.pad(np.nan_to_num(row), (3080 - len(row), 0))\n",
    "\n",
    "merge = pd.read_csv(\"merge.csv\")\n",
    "merge = merge.sort_values(['longitude', 'latitude'])\n",
    "merge['datetime'] = pd.to_datetime(merge['datetime'])\n",
    "merge = merge.loc[merge['datetime'].apply(lambda value: value.minute % 10 == 0)]\n",
    "grouped = merge.groupby('datetime')\n",
    "\n",
    "wind = grouped['speed'].apply(process).to_list()\n",
    "fire = grouped['Power'].apply(process).to_list()\n",
    "wind = normalize(wind) * 10\n",
    "fire = normalize(fire) * 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T20:06:27.827994Z",
     "start_time": "2023-11-11T20:06:20.446958Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define and train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_count):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        feature_cnt = np.linspace(input_size, output_size, hidden_count, dtype=int)\n",
    "        self.layers = nn.ModuleList([nn.Linear(feature_cnt[i], feature_cnt[i + 1]) for i in range(len(feature_cnt) - 1)])\n",
    "        print(self.layers)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if i < len(self.layers) - 1:\n",
    "                x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size // 2\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_channels + self.hidden_channels,\n",
    "                              out_channels=4 * self.hidden_channels,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding)\n",
    "\n",
    "    def forward(self, input, hidden_state):\n",
    "        hidden, cell_state = hidden_state\n",
    "        combined = torch.cat((input, hidden), dim=1)\n",
    "        gates = self.conv(combined)\n",
    "\n",
    "        # Split the combined tensor into 4 separate tensors\n",
    "        ingate, forgetgate, cellgate, outgate = torch.split(gates, self.hidden_channels, dim=1)\n",
    "\n",
    "        ingate = torch.sigmoid(ingate)\n",
    "        forgetgate = torch.sigmoid(forgetgate)\n",
    "        cellgate = torch.tanh(cellgate)\n",
    "        outgate = torch.sigmoid(outgate)\n",
    "\n",
    "        cell_state = (forgetgate * cell_state) + (ingate * cellgate)\n",
    "        hidden_state = outgate * torch.tanh(cell_state)\n",
    "\n",
    "        return hidden_state, cell_state\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.from_numpy(features).float()\n",
    "        self.labels = torch.from_numpy(labels).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T20:06:27.834912Z",
     "start_time": "2023-11-11T20:06:27.833272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, criterion, optimizer, num_epochs):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        test_loss.append(test(model, criterion, test_loader))\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs, None)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss.append(total_loss)\n",
    "\n",
    "        # Print the average loss for this epoch\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "    return train_loss, test_loss\n",
    "\n",
    "\n",
    "def test(model: MLP, criterion, dl):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(dl):\n",
    "        predicted = model(inputs)\n",
    "        loss = criterion(predicted, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T20:06:27.840073Z",
     "start_time": "2023-11-11T20:06:27.838004Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1313, 6160)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ConvLSTM' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m loss_func \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[1;32m     15\u001B[0m model \u001B[38;5;241m=\u001B[39m ConvLSTM(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m)\n\u001B[1;32m     17\u001B[0m train_loss, test_loss \u001B[38;5;241m=\u001B[39m train(model, train_dl, test_dl, loss_func, optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m), epochs)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_loss\u001B[39m(train_loss, test_loss):\n",
      "File \u001B[0;32m~/PycharmProjects/ProjectNebulus/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1696\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1694\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1695\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1696\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'ConvLSTM' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = np.hstack((fire, wind))\n",
    "print(\"Data shape:\", data.shape)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data[:-1], fire[1:])\n",
    "train_dl = DataLoader(CustomDataset(train_x, train_y), batch_size=10, shuffle=True)\n",
    "test_dl = DataLoader(CustomDataset(test_x, test_y), batch_size=10, shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "loss_func = nn.MSELoss()\n",
    "model = ConvLSTM(2, 2, 5)\n",
    "print(model.layers)\n",
    "train_loss, test_loss = train(model, train_dl, test_dl, loss_func, optim.Adam(model.parameters(), lr=0.01), epochs)\n",
    "\n",
    "\n",
    "def plot_loss(train_loss, test_loss):\n",
    "    plt.plot(range(1, len(train_loss) + 1), train_loss, label=\"Training loss\")\n",
    "    plt.plot(range(1, len(test_loss) + 1), test_loss, label=\"Test loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss ($L2$)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_loss(train_loss, test_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T20:06:27.955240Z",
     "start_time": "2023-11-11T20:06:27.844549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "arr = fire[1300]\n",
    "arr[arr == 0] = np.nan\n",
    "axis = plt.matshow(arr.reshape(55, 56), fignum=fig, cmap=\"autumn_r\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T20:06:27.960924Z",
     "start_time": "2023-11-11T20:06:27.956836Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
